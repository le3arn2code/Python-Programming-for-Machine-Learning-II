# Lab 2: Data Preprocessing with Pandas

## Objective
You will:
1) Load a dataset using Pandas  
2) Handle missing values  
3) Normalize numerical data (Min–Max)  
4) Split data into train/test sets

---

## Prerequisites (fresh VM)
Install with your preferred method (**no apt upgrade**, pip with break-system packages):
```bash
pip3 install --break-system-packages pandas scikit-learn
```
Optional: If you don't have `iris.csv`, use the helper to generate it locally (see below).

---

## Step-by-Step (nano friendly)

### Step 1 — Prepare working directory
```bash
cd ~
mkdir -p lab02 && cd lab02
```

### Step 2 — (If needed) Generate iris.csv
```bash
nano generate_iris_csv.py
```
Paste and save the script from this lab, then:
```bash
python3 generate_iris_csv.py
ls -lh iris.csv
```

### Step 3 — Create the preprocessing script
```bash
nano data_preprocessing.py
```
Paste and save the script from this lab.

### Step 4 — Run
```bash
python3 data_preprocessing.py
```

### Step 5 — Verify
You should see:
- Head of the dataset
- Slice showing introduced NaNs and the same slice after filling
- Normalized head (values in 0..1 for numeric columns)
- Shapes near:
```
Training data shape: (120, 4)
Testing data shape: (30, 4)
```

The screenshot `screenshots/lab02_output_terminal.png` from our run is included.

---

## Files
- `generate_iris_csv.py` — creates `iris.csv` locally (classic format, no header)
- `data_preprocessing.py` — the lab script
- `commands.sh` — nano-friendly commands
- `troubleshooting.md` — errors/warnings we hit and how we fixed them
- `interview_qna.md` — 10 Q&A with answers
- `layman_explanation.md` — plain-English explanation
- `screenshots/` — includes your terminal screenshot
- `iris.csv` — generated by helper (if you used it)

---

## Conclusion
You’ve cleaned and prepared data for ML: handled missing values, scaled features, and created train/test splits.